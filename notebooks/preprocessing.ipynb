{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3d46500",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b985fc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00df7493",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/sentimentdataset_mapped.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723bc751",
   "metadata": {},
   "source": [
    "### Looking through the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "510d5afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 732 entries, 0 to 731\n",
      "Data columns (total 16 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Unnamed: 0.1     732 non-null    int64  \n",
      " 1   Unnamed: 0       732 non-null    int64  \n",
      " 2   Text             732 non-null    object \n",
      " 3   Sentiment        732 non-null    object \n",
      " 4   Timestamp        732 non-null    object \n",
      " 5   User             732 non-null    object \n",
      " 6   Platform         732 non-null    object \n",
      " 7   Hashtags         732 non-null    object \n",
      " 8   Retweets         732 non-null    float64\n",
      " 9   Likes            732 non-null    float64\n",
      " 10  Country          732 non-null    object \n",
      " 11  Year             732 non-null    int64  \n",
      " 12  Month            732 non-null    int64  \n",
      " 13  Day              732 non-null    int64  \n",
      " 14  Hour             732 non-null    int64  \n",
      " 15  Sentiment_clean  732 non-null    object \n",
      "dtypes: float64(2), int64(6), object(8)\n",
      "memory usage: 91.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4b56710",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['Text', 'Sentiment_clean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee207c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text               0\n",
       "Sentiment_clean    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c95567",
   "metadata": {},
   "source": [
    "#### Getting rid of duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bc63a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated(subset=['Text']).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cffe1def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "data = data.drop_duplicates(subset=['Text']).reset_index(drop=True)\n",
    "print(data.duplicated(subset=['Text']).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "054794af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment_clean\n",
       "Positive    413\n",
       "Negative    162\n",
       "Neutral     131\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Sentiment_clean'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484cb089",
   "metadata": {},
   "source": [
    "### Tokenizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4449d6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f90492de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()  \n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3c890fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Clean_Text'] = data['Text'].astype(str).apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68da7368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment_clean</th>\n",
       "      <th>Clean_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Enjoying a beautiful day at the park!</td>\n",
       "      <td>Positive</td>\n",
       "      <td>enjoying beautiful day park</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Traffic was terrible this morning.</td>\n",
       "      <td>Negative</td>\n",
       "      <td>traffic terrible morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Just finished an amazing workout! ðŸ’ª</td>\n",
       "      <td>Positive</td>\n",
       "      <td>finished amazing workout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Excited about the upcoming weekend getaway!</td>\n",
       "      <td>Positive</td>\n",
       "      <td>excited upcoming weekend getaway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trying out a new recipe for dinner tonight.</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>trying new recipe dinner tonight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>Collaborating on a science project that receiv...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>collaborating science project received recogni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>Attending a surprise birthday party organized ...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>attending surprise birthday party organized fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>Successfully fundraising for a school charity ...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>successfully fundraising school charity initia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>Participating in a multicultural festival, cel...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>participating multicultural festival celebrati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>Organizing a virtual talent show during challe...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>organizing virtual talent show challenging tim...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>706 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text Sentiment_clean  \\\n",
       "0                Enjoying a beautiful day at the park!        Positive   \n",
       "1                   Traffic was terrible this morning.        Negative   \n",
       "2                  Just finished an amazing workout! ðŸ’ª        Positive   \n",
       "3          Excited about the upcoming weekend getaway!        Positive   \n",
       "4          Trying out a new recipe for dinner tonight.         Neutral   \n",
       "..                                                 ...             ...   \n",
       "701  Collaborating on a science project that receiv...         Neutral   \n",
       "702  Attending a surprise birthday party organized ...         Neutral   \n",
       "703  Successfully fundraising for a school charity ...         Neutral   \n",
       "704  Participating in a multicultural festival, cel...         Neutral   \n",
       "705  Organizing a virtual talent show during challe...         Neutral   \n",
       "\n",
       "                                            Clean_Text  \n",
       "0                          enjoying beautiful day park  \n",
       "1                             traffic terrible morning  \n",
       "2                             finished amazing workout  \n",
       "3                     excited upcoming weekend getaway  \n",
       "4                     trying new recipe dinner tonight  \n",
       "..                                                 ...  \n",
       "701  collaborating science project received recogni...  \n",
       "702  attending surprise birthday party organized fr...  \n",
       "703  successfully fundraising school charity initia...  \n",
       "704  participating multicultural festival celebrati...  \n",
       "705  organizing virtual talent show challenging tim...  \n",
       "\n",
       "[706 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d0fdb3",
   "metadata": {},
   "source": [
    "### Saving the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe2e5173",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['Clean_Text', 'Sentiment_clean']].to_csv('../data/preprocessed_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
